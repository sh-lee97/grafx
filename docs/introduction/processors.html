<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Batched Audio Processing" href="render.html" /><link rel="prev" title="Audio Processing Graphs" href="graph.html" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/><!-- Generated with Sphinx 7.4.7 and Furo 2024.07.18 -->
        <title>Differentiable Processors - GRAFX Documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=613ab9ff" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=a6743078" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">GRAFX Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">GRAFX Documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="graph.html">Audio Processing Graphs</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Differentiable Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="render.html">Batched Audio Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Graph API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../graph_api/data.html">grafx.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graph_api/render.html">grafx.render</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graph_api/draw.html">grafx.draw</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graph_api/utils.html">grafx.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Processor API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/core.html">grafx.processors.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/filter.html">grafx.processors.filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/eq.html">grafx.processors.eq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/stereo.html">grafx.processors.stereo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/dynamics.html">grafx.processors.dynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/reverb.html">grafx.processors.reverb</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/delay.html">grafx.processors.delay</a></li>
<li class="toctree-l1"><a class="reference internal" href="../processor_api/container.html">grafx.processors.container</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../references/history.html">Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/reference.html">References</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="differentiable-processors">
<span id="id1"></span><h1>Differentiable Processors<a class="headerlink" href="#differentiable-processors" title="Link to this heading"></a></h1>
<p>We can import to or approximate the conventional audio processors,
building blocks of the audio processing graphs,
in the automatic differentiation framework
(<code class="code highlight python docutils literal highlight-python"><span class="n">PyTorch</span></code> for our case).
This practice is known as <em>differentiable digital signal processing</em> <span id="id2">[<a class="reference internal" href="../references/reference.html#id8" title="Jesse Engel, Lamtharn (Hanoi) Hantrakul, Chenjie Gu, and Adam Roberts. DDSP: differentiable digital signal processing. In ICLR. 2020.">EHGR20</a>, <a class="reference internal" href="../references/reference.html#id105" title="Ben Hayes, Jordie Shier, Gyorgy Fazekas, Andrew McPherson, and Charalampos Saitis. A review of differentiable digital signal processing for music &amp; speech synthesis. Frontiers in Signal Process., pages 1284100, 2023.">HSF+23</a>]</span>,
or DDSP in short.
The differentiable processors have the following advantages.</p>
<ol class="arabic simple">
<li><p>Recall that many works
<span id="id3">[<a class="reference internal" href="../references/reference.html#id139" title="Franco Caspe, Andrew McPherson, and Mark Sandler. DDX7: differentiable FM synthesis of musical instrument sounds. In ISMIR. 2022.">CMS22</a>, <a class="reference internal" href="../references/reference.html#id70" title="J Colonel. Music production behaviour modelling. 2023.">Col23</a>, <a class="reference internal" href="../references/reference.html#id132" title="Jinyue Guo and Brian McFee. Automatic recognition of cascaded guitar effects. In DAFx. 2023.">GM23</a>, <a class="reference internal" href="../references/reference.html#id148" title="Sungho Lee, Marco A Martinez-Ramirez, Wei-Hsiang Liao, Stefan Uhlich, Giorgio Fabbro, Kyogu Lee, and Yuki Mitsufuji. Searching for music mixing graphs: a pruning approach. In DAFx. 2024.">LMRL+24a</a>, <a class="reference internal" href="../references/reference.html#id65" title="Sungho Lee, Jaehyun Park, Seungryeol Paik, and Kyogu Lee. Blind estimation of audio processing graph. In IEEE ICASSP, 1–5. 2023.">LPPL23</a>, <a class="reference internal" href="../references/reference.html#id140" title="Marco A Martinez-Ramirez, Oliver Wang, Paris Smaragdis, and Nicholas J Bryan. Differentiable signal processing with black-box audio effects. In IEEE ICASSP. 2021.">MRWSB21</a>, <a class="reference internal" href="../references/reference.html#id18" title="Christopher Mitcheltree and Hideki Koike. SerumRNN: step by step audio VST effect programming. In Artificial Intelligence in Music, Sound, Art and Design, pages 218–234. 2021.">MK21</a>, <a class="reference internal" href="../references/reference.html#id4" title="Christian J. Steinmetz, Jordi Pons, Santiago Pascual, and Joan Serrà. Automatic multitrack mixing with a differentiable mixing console of neural audio effects. In IEEE ICASSP, volume, 71-75. 2021.">SPPS21</a>, <a class="reference internal" href="../references/reference.html#id134" title="Noy Uzrad and others. DiffMoog: a differentiable modular synthesizer for sound matching. arXiv:2401.12570, 2024.">U+24</a>, <a class="reference internal" href="../references/reference.html#id95" title="Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, and Yike Guo. NAS-FM: neural architecture search for tunable and interpretable sound synthesis based on frequency modulation. arXiv:2305.12868, 2023.">YXT+23</a>]</span>
involves a parameter estimation task.
With the differentiable processors, we can optimize these parameters (or their neural predictors)
by comparing the processed audio <span class="math notranslate nohighlight">\(\smash{\hat{\mathbf{Y}}} = G(\mathbf{S}, \mathbf{P})\)</span> and the target <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>
and back-propagating the gradients through the entire processing graph <span class="math notranslate nohighlight">\(G\)</span>
(commonly refered as <em>end-to-end</em> optimization).</p></li>
<li><p>As they are identical to or approximate the real-world processors that the practitioners are familiar with,
the obtained parameters are easy to interpret and control.
Of course, our framework can be used with any neural network that provides the gradients;
the differentiable processors just suit more to the compositional and interpretable nature of the audio processing graph.</p></li>
</ol>
<p>On this page, we share how we implemented and handled such processors within <code class="code highlight python docutils literal highlight-python"><span class="n">GRAFX</span></code> framework.</p>
<section id="batched-processing">
<h2>Batched Processing<a class="headerlink" href="#batched-processing" title="Link to this heading"></a></h2>
<p>In the previous section, we defined the processor <span class="math notranslate nohighlight">\(f\)</span>, as a node <span class="math notranslate nohighlight">\(v \in V\)</span> with type <span class="math notranslate nohighlight">\(t\)</span>,
that outputs audio from input signals and parameters.
Here, we introduce a notation for the batched processing of the processor <span class="math notranslate nohighlight">\(f\)</span>.
Assume that there is a node subset <span class="math notranslate nohighlight">\(Q \subset V_t\)</span> that consists of the type-<span class="math notranslate nohighlight">\(t\)</span> processors.
Instead of processing <span class="math notranslate nohighlight">\(|Q|\)</span> nodes independently, we can process them with a single processor <span class="math notranslate nohighlight">\(f\)</span> that takes the batched input signals and parameters.
We write this as follows,
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
\mathbf{Y}^{(1)}_{Q}, \cdots, \mathbf{Y}^{(N)}_{Q}
= f\!\left(\mathbf{U}^{(1)}_{Q}, \cdots, \mathbf{U}^{(M)}_{Q}, \mathbf{P}_{Q}\right).
\]</div>
</div>
</p>
<p>Here, <span class="math notranslate nohighlight">\(\smash{\mathbf{U}^{(m)}_{Q} \in \mathbb{R}^{\left| Q \right|\times C\times L}}\)</span>
is a stack of subset nodes’ input signals for the <span class="math notranslate nohighlight">\(m^\mathrm{th}\)</span> inlet.
The parameters <span class="math notranslate nohighlight">\(\smash{\mathbf{P}_{Q}}\)</span> are stacked in a similar manner
with each tensor having the first dimension of size <span class="math notranslate nohighlight">\(|Q|\)</span>.
Note that the node order in parameter tensors must be the same as the one in the input signals.
The output returned by the processor
<span class="math notranslate nohighlight">\(\smash{\mathbf{Y}^{(n)}_{Q} \in \mathbb{R}^{\left| Q \right|\times C\times L}}\)</span> are also stacked the same way as the input.
In the remaining documentation, this arbitrary batching is always assumed, and the subscript <span class="math notranslate nohighlight">\(Q\)</span> is dropped for brevity,
unless we need to emphasize it.</p>
<section id="parameter-gradients">
<h3>Parameter Gradients<a class="headerlink" href="#parameter-gradients" title="Link to this heading"></a></h3>
<p>A differentiable processor <span class="math notranslate nohighlight">\(f\)</span> should be able to compute the gradients of the output audio
with respect to its input audio and parameters.
We denote these gradients as
<span class="math notranslate nohighlight">\(\nabla_p \mathbf{Y}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(\nabla_{\mathbf{U}^{(m)}} \mathbf{Y}^{(n)}\)</span>, respectively, for all <span class="math notranslate nohighlight">\(m\)</span>, <span class="math notranslate nohighlight">\(n\)</span>, and <span class="math notranslate nohighlight">\(p \in \mathbf{P}\)</span>
(<span class="math notranslate nohighlight">\(Q\)</span> omitted).
If every processor provides these gradients, after computing the graph output <span class="math notranslate nohighlight">\(\mathbf{Y} = G(\mathbf{S}, \mathbf{P})\)</span>,
we can backpropagate through the entire graph <span class="math notranslate nohighlight">\(G\)</span> and optimize the parameters <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> via chain rule.</p>
<blockquote>
<div><p>While it is not our primary focus, we can also obtain the gradients w.r.t. the input source signals <span class="math notranslate nohighlight">\(\mathbf{S}\)</span>.
These gradients are useful in some scenarios, e.g.,
when we want to solve an inverse problem with pre-trained diffusion models <span id="id4">[<a class="reference internal" href="../references/reference.html#id154" title="Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L Klasky, and Jong Chul Ye. Diffusion posterior sampling for general noisy inverse problems. arXiv preprint arXiv:2209.14687, 2022.">CKM+22</a>]</span>.
Some recent works on audio watermarking also utilize such gradients <span id="id5">[<a class="reference internal" href="../references/reference.html#id152" title="Guangyu Chen, Yu Wu, Shujie Liu, Tao Liu, Xiaoyong Du, and Furu Wei. Wavmark: watermarking for audio generation. arXiv preprint arXiv:2308.12770, 2023.">CWL+23</a>, <a class="reference internal" href="../references/reference.html#id153" title="Robin San Roman, Pierre Fernandez, Alexandre Défossez, Teddy Furon, Tuan Tran, and Hady Elsahar. Proactive detection of voice cloning with localized watermarking. arXiv preprint arXiv:2401.17264, 2024.">RFDefossez+24</a>]</span>.
Finally, instead of the source <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> and parameters <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>,
we might want to obtain gradients w.r.t. the <em>graph structure</em> <span class="math notranslate nohighlight">\(G\)</span>.
It is not directly possible, as the graph structure is inherently discrete, but we may obtain the gradients
w.r.t. the relaxed continuous representation (of some structural modifications).
Notable examples include the graph pruning via soft gating mechanism <span id="id6">[<a class="reference internal" href="../references/reference.html#id131" title="Hongrong Cheng, Miao Zhang, and Javen Qinfeng Shi. A survey on deep neural network pruning-taxonomy, comparison, analysis, and recommendations. arXiv:2308.06767, 2023.">CZS23</a>, <a class="reference internal" href="../references/reference.html#id108" title="Yang He and Lingao Xiao. Structured pruning for deep convolutional neural networks: a survey. arXiv:2303.00566, 2023.">HX23</a>, <a class="reference internal" href="../references/reference.html#id148" title="Sungho Lee, Marco A Martinez-Ramirez, Wei-Hsiang Liao, Stefan Uhlich, Giorgio Fabbro, Kyogu Lee, and Yuki Mitsufuji. Searching for music mixing graphs: a pruning approach. In DAFx. 2024.">LMRL+24a</a>]</span>,
which also can be generalized into the <em>differentiable artitecture search (DARTS)</em> framework <span id="id7">[<a class="reference internal" href="../references/reference.html#id89" title="Hanxiao Liu, Karen Simonyan, and Yiming Yang. DARTS: differentiable architecture search. In ICLR. 2019.">LSY19</a>, <a class="reference internal" href="../references/reference.html#id95" title="Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, and Yike Guo. NAS-FM: neural architecture search for tunable and interpretable sound synthesis based on frequency modulation. arXiv:2305.12868, 2023.">YXT+23</a>]</span>.</p>
</div></blockquote>
</section>
<section id="about-this-ddsp-business">
<h3>About this DDSP Business<a class="headerlink" href="#about-this-ddsp-business" title="Link to this heading"></a></h3>
<p>Due to the aforementioned chain rule, every processor in the graph must provide the gradients:
<span class="math notranslate nohighlight">\(\nabla_p \mathbf{Y}^{(n)}\)</span> and <span class="math notranslate nohighlight">\(\nabla_{\mathbf{U}^{(m)}} \mathbf{Y}^{(n)}\)</span>.
If the one processor does not provide the former, we cannot optimize its parameters <span class="math notranslate nohighlight">\(p\)</span>.
If the latter is not available, the backpropagation stops at that node <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p>Moreover, it is desirable to compute these gradients in GPU efficiently,
this is not so straightforward for some processors.
To address this, various approximation methods have been proposed;
one notable example is the frequency sampling method that eliminates
the linear recurrent loop in the infinite impulse response filters
<span id="id8">[<a class="reference internal" href="../references/reference.html#id24" title="Sungho Lee, Hyeong-Seok Choi, and Kyogu Lee. Differentiable artificial reverberation. IEEE/ACM TASLP, 30:2541–2556, 2022.">LCL22</a>, <a class="reference internal" href="../references/reference.html#id83" title="Shahan Nercessian. Neural parametric equalizer matching using differentiable biquads. In DAFx, 265–272. 2020.">Ner20</a>]</span>.
Approximation of dynamic range compressors, which contain nonlinear recurrent loops,
has been also proposed <span id="id9">[<a class="reference internal" href="../references/reference.html#id70" title="J Colonel. Music production behaviour modelling. 2023.">Col23</a>, <a class="reference internal" href="../references/reference.html#id78" title="Joseph T Colonel, Marco Comunita, and Joshua Reiss. Reverse engineering memoryless distortion effects with differentiable waveshapers. In AES Convention 153. 2022.">CCR22</a>, <a class="reference internal" href="../references/reference.html#id77" title="Christian J Steinmetz, Nicholas J Bryan, and Joshua D Reiss. Style transfer of audio effects with differentiable signal processing. JAES, 70(9):708–721, 2022.">SBR22</a>]</span>.</p>
<p>Sometimes, the analytical gradients are simply not available, e.g., ones that include black-boxes or discrete operations.
In this case, we can still resort to finite difference methods <span id="id10">[<a class="reference internal" href="../references/reference.html#id121" title="Marco A Martinez Ramirez, Emmanouil Benetos, and Joshua D Reiss. Deep learning for black-box modeling of audio effects. Applied Sciences, 10(2):638, 2020.">MRBR20</a>]</span>, straight-through estimators <span id="id11">[<a class="reference internal" href="../references/reference.html#id13" title="Yoshua Bengio, Nicholas Leonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv:1308.3432, 2013.">BLC13</a>]</span>,
or use a pre-trained auxiliary neural network that mimics the processors <span id="id12">[<a class="reference internal" href="../references/reference.html#id4" title="Christian J. Steinmetz, Jordi Pons, Santiago Pascual, and Joan Serrà. Automatic multitrack mixing with a differentiable mixing console of neural audio effects. In IEEE ICASSP, volume, 71-75. 2021.">SPPS21</a>]</span> to approximate the gradients.
In the literature, these approaches are also referred to as “differentiable;” hence making it an umbrella term encompassing all practical methods that obtain the output signals, gradients, or their approximates of the processors of interest.</p>
<p>Our parameter gradient <span class="math notranslate nohighlight">\(\nabla_\mathbf{P} L\)</span> is a function <span class="math notranslate nohighlight">\(h\)</span> of not only the graph <span class="math notranslate nohighlight">\(G\)</span> and the current parameter <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>,
but also the signals (the source <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> if exists and the target <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>) and the loss function <span class="math notranslate nohighlight">\(L\)</span>.
By slightly abusing the notation of partial derivatives, we can write the gradient as follows,
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[
\nabla_\mathbf{P} L = h(\mathbf{P}; G, \mathbf{Y}, \mathbf{S}, L)
= \frac{\partial G(\mathbf{S}; \mathbf{P})}{\partial \mathbf{P}} \frac{\partial L(\mathbf{Y}, G(\mathbf{S}; \mathbf{P}))}{\partial G(\mathbf{S}; \mathbf{P})}.
\]</div>
</div>
</p>
<p>This indicates that, even if the model <span class="math notranslate nohighlight">\(G\)</span> itself is very simple, its gradients can be highly nonconvex,
hindering the optimization.
One notable example is the unconstrained sinusoid model;
it is still an unsolved problem to optimize the amplitude, frequency, and phase of the sinusoids
so that their sum matches the target audio.
To mitigate this, a surrogate model <span class="math notranslate nohighlight">\(\smash{\tilde G}\)</span> is introduced <span id="id13">[<a class="reference internal" href="../references/reference.html#id85" title="Ben Hayes, Charalampos Saitis, and György Fazekas. Sinusoidal frequency estimation by gradient descent. In IEEE ICASSP, 1–5. 2023.">HSF23</a>]</span>
or a novel loss function <span class="math notranslate nohighlight">\(L\)</span> is designed <span id="id14">[<a class="reference internal" href="../references/reference.html#id156" title="Simon Schwar and Meinard Muller. Multi-scale spectral loss revisited. IEEE Signal Processing Letters, 30:1712–1716, 2023.">SM23</a>, <a class="reference internal" href="../references/reference.html#id155" title="Bernardo Torres, Geoffroy Peeters, and Gaël Richard. Unsupervised harmonic parameter estimation using differentiable dsp and spectral optimal transport. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1176–1180. IEEE, 2024.">TPR24</a>]</span>,
albeit none of them completely solves the problem.</p>
<p>For more details, refer to the recent review <span id="id15">[<a class="reference internal" href="../references/reference.html#id105" title="Ben Hayes, Jordie Shier, Gyorgy Fazekas, Andrew McPherson, and Charalampos Saitis. A review of differentiable digital signal processing for music &amp; speech synthesis. Frontiers in Signal Process., pages 1284100, 2023.">HSF+23</a>]</span>, ISMIR tutorial <a class="reference external" href="https://intro2ddsp.github.io/intro.html">“Introduction to DDSP for Audio Synthesis,”</a> and references therein.</p>
</section>
</section>
<section id="implementation-details">
<h2>Implementation Details<a class="headerlink" href="#implementation-details" title="Link to this heading"></a></h2>
<p>Following the standard practice, our dfferentiable processors inherit <code class="code highlight python docutils literal highlight-python"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></code>.
For example, see the implementation of <a class="reference internal" href="../processor_api/stereo.html#grafx.processors.stereo.StereoGain" title="grafx.processors.stereo.StereoGain"><code class="xref py py-class docutils literal notranslate"><span class="pre">StereoGain</span></code></a>,
which applies channel-wise gain to a batch of (mono or stereo) signals, resulting in a panning effect.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">StereoGain</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_signals</span><span class="p">,</span> <span class="n">log_gain</span><span class="p">):</span>
        <span class="n">gain</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_gain</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">output_signals</span> <span class="o">=</span> <span class="n">input_signals</span> <span class="o">*</span> <span class="n">gain</span>
        <span class="k">return</span> <span class="n">output_signals</span>

    <span class="k">def</span> <span class="nf">parameter_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;log_gain&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
</pre></div>
</div>
<section id="forward-pass">
<h3>Forward Pass<a class="headerlink" href="#forward-pass" title="Link to this heading"></a></h3>
<p>Each processor accepts <em>both</em> input signal(s) and (collection of) parameters for each forward pass with a signature of
<code class="code highlight python docutils literal highlight-python"><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="n">input_signals</span><span class="p">,</span> <span class="o">**</span><span class="n">processor_parameters</span><span class="p">)</span></code>.
Observe that we do not store the processor parameters (e.g., as a <code class="code highlight python docutils literal highlight-python"><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span></code>) internally;
only the fixed buffers or hyperparameters are stored as class attributes.
This approach avoids creating multiple processor instances of type <span class="math notranslate nohighlight">\(t\)</span>
and allows processing of any batched input tensors, <span class="math notranslate nohighlight">\(\mathbf{P}_{Q}\)</span>,
of an arbitrary node subset <span class="math notranslate nohighlight">\(Q \subset V_t\)</span>.
Also, exposing the parameters makes the implementation of parameter gradient descent
and training of the neural networks as parameter predictors almost identical.
Along with the outputs, one can also return a dictionary
(e.g., containing regularization terms) as a second return value,
which will be collected when we compute the graph output.</p>
</section>
<section id="parameter-shapes">
<h3>Parameter Shapes<a class="headerlink" href="#parameter-shapes" title="Link to this heading"></a></h3>
<p>We also implement the <code class="code highlight python docutils literal highlight-python"><span class="n">parameter_size</span><span class="p">()</span></code> method, which returns the shape of each parameter tensor in a dictionary format.
Note that it returns the tensor shapes <em>without</em> the batch (or node) dimension.
While this method is not essential, it is useful for initializing parameters for the gradient descent or creating a prediction head for the neural network.</p>
<p>For example, to perform a gradient descent of the given graph’s parameters,
we first prepare the processors in a dictionary format,
where each key is the processor name (one provided to the config)
and its value is a processor instance.
This approach will also be used to render the output audio (described in the following page),</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">grafx.processors</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ZeroPhaseFIREqualizer</span><span class="p">,</span>
    <span class="n">ApproxCompressor</span><span class="p">,</span>
    <span class="n">MidSideFilteredNoiseReverb</span>
<span class="p">)</span>

<span class="n">processors</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;eq&quot;</span><span class="p">:</span> <span class="n">ZeroPhaseFIREqualizer</span><span class="p">(),</span>
    <span class="s2">&quot;compressor&quot;</span><span class="p">:</span> <span class="n">ApproxCompressor</span><span class="p">(),</span>
    <span class="s2">&quot;reverb&quot;</span><span class="p">:</span> <span class="n">MidSideFilteredNoiseReverb</span><span class="p">()</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Then, we use a <a class="reference internal" href="../graph_api/utils.html#grafx.utils.create_empty_parameters" title="grafx.utils.create_empty_parameters"><code class="xref py py-func docutils literal notranslate"><span class="pre">create_empty_parameters()</span></code></a> method that creates an empty parameter dictionary from the graph tensor <code class="code highlight python docutils literal highlight-python"><span class="n">G_t</span></code> and its processors.
Here, the graph <code class="code highlight python docutils literal highlight-python"><span class="n">G_t</span></code> is the one we created in the last page, containing three equalizers, compressors, and reverbs.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>from<span class="w"> </span>grafx.utils<span class="w"> </span>import<span class="w"> </span>create_empty_parameters
<span class="nv">parameters</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>create_empty_parameters<span class="o">(</span>G_t,<span class="w"> </span>processors<span class="o">)</span>
</pre></div>
</div>
<p>The returned <code class="code highlight python docutils literal highlight-python"><span class="n">parameters</span></code> will have a nested dictioary format,
where the first key is the processor name and the second key is the parameter name.
Note that we use <code class="code highlight python docutils literal highlight-python"><span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span></code> and <code class="code highlight python docutils literal highlight-python"><span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span></code> to store the parameters, instead of the default <code class="code highlight python docutils literal highlight-python"><span class="nb">dict</span></code>.
We can check the shapes of the parameters with <code class="code highlight python docutils literal highlight-python"><span class="nb">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span></code> and the outputs will be as follows.
Observe that the first dimension of each tensor is the number of nodes of that type in the graph, i.e., three in this case.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ModuleDict<span class="o">(</span>
<span class="w">    </span><span class="o">(</span>eq<span class="o">)</span>:<span class="w"> </span>ParameterDict<span class="o">(</span>
<span class="w">        </span><span class="o">(</span>log_magnitude<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x1024<span class="o">]</span>
<span class="w">    </span><span class="o">)</span>
<span class="w">    </span><span class="o">(</span>compressor<span class="o">)</span>:<span class="w"> </span>ParameterDict<span class="o">(</span>
<span class="w">        </span><span class="o">(</span>log_knee<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x1<span class="o">]</span>
<span class="w">        </span><span class="o">(</span>log_ratio<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x1<span class="o">]</span>
<span class="w">        </span><span class="o">(</span>log_threshold<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x1<span class="o">]</span>
<span class="w">        </span><span class="o">(</span>z_alpha<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x1<span class="o">]</span>
<span class="w">    </span><span class="o">)</span>
<span class="w">    </span><span class="o">(</span>reverb<span class="o">)</span>:<span class="w"> </span>ParameterDict<span class="o">(</span>
<span class="w">        </span><span class="o">(</span>delta_log_magnitude<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x2x193<span class="o">]</span>
<span class="w">        </span><span class="o">(</span>init_log_magnitude<span class="o">)</span>:<span class="w"> </span>Parameter<span class="w"> </span>containing:<span class="w"> </span><span class="o">[</span>torch.FloatTensor<span class="w"> </span>of<span class="w"> </span>size<span class="w"> </span>3x2x193<span class="o">]</span>
<span class="w">    </span><span class="o">)</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="render.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Batched Audio Processing</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="graph.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Audio Processing Graphs</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Sungho Lee
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Differentiable Processors</a><ul>
<li><a class="reference internal" href="#batched-processing">Batched Processing</a><ul>
<li><a class="reference internal" href="#parameter-gradients">Parameter Gradients</a></li>
<li><a class="reference internal" href="#about-this-ddsp-business">About this DDSP Business</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-details">Implementation Details</a><ul>
<li><a class="reference internal" href="#forward-pass">Forward Pass</a></li>
<li><a class="reference internal" href="#parameter-shapes">Parameter Shapes</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>